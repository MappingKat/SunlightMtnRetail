{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41896ce4",
   "metadata": {},
   "source": [
    "## 2. Pre-processing and Training Data Development\n",
    "\n",
    "This stage comes in three parts:\n",
    "\n",
    "I. Create dummy or indicator features for categorical variables (categories -- one hot encoding)\n",
    "\n",
    "II. Standardize the magnitude of numeric features using a scaler (MSRP, Cost)\n",
    "\n",
    "III. Split your data into testing and training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ce401d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'products' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 18\u001b[0m\n\u001b[1;32m      8\u001b[0m new_categories \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBike - Complete Bikes\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBike - Parts\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBike - Accessories\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSki Hardgoods - Skis\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSki Hardgoods - Boots\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSki Hardgoods - Bindings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHealth Care/Medicine\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m ]\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Separate features and target variable\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m features \u001b[38;5;241m=\u001b[39m products\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_variable\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Drop target\u001b[39;00m\n\u001b[1;32m     19\u001b[0m target \u001b[38;5;241m=\u001b[39m products[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_variable\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Create dummy features for new categories\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'products' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assuming your cleaned and explored product data is in a DataFrame called 'products'\n",
    "\n",
    "# New category list (replace with your actual list if different)\n",
    "new_categories = pd.read_csv(\"../data/processed/sunligh-categories.csv\") \n",
    "\n",
    "# Separate features and target variable\n",
    "features = products.drop('target_variable', axis=1)  # Drop target\n",
    "target = products['target_variable']\n",
    "\n",
    "# Create dummy features for new categories\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "encoded_features = pd.DataFrame(encoder.fit_transform(features['Category'].str.split(' - ').tolist()))\n",
    "\n",
    "# Select relevant features (optional, adjust based on your data)\n",
    "relevant_features = ['Brand', 'Description', 'StyleName'] + list(encoded_features.columns)\n",
    "features = features[relevant_features]\n",
    "\n",
    "# Standardize numeric features (if any)\n",
    "scaler = StandardScaler()\n",
    "try:\n",
    "  # Attempt to fit scaler on numeric columns\n",
    "  numerical_cols = features.select_dtypes(include=['int64', 'float64'])\n",
    "  scaled_features = pd.concat([scaler.fit_transform(numerical_cols), features.drop(numerical_cols, axis=1)], axis=1)\n",
    "except ValueError:\n",
    "  # If no numeric columns, use the features as is\n",
    "  scaled_features = features.copy()\n",
    "\n",
    "# Split data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Now you have:\n",
    "# - X_train: Training features (scaled)\n",
    "# - X_test: Testing features (scaled)\n",
    "# - y_train: Training target variable\n",
    "# - y_test: Testing target variable\n",
    "\n",
    "# You can use these for model training and evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75904d9f",
   "metadata": {},
   "source": [
    "Resources: \n",
    "\n",
    "- [blog post](https://towardsdatascience.com/document-embedding-techniques-fed3e7a6a25d)\n",
    "- [textcategorizer](https://spacy.io/api/textcategorizer)\n",
    "- [doc2vec](https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html#sphx-glr-auto-examples-tutorials-run-doc2vec-lee-py)\n",
    "- [vec regression](https://towardsdatascience.com/multi-class-text-classification-with-doc2vec-logistic-regression-9da9947b43f4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4f8d7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Libraries\n"
     ]
    }
   ],
   "source": [
    "# data manipulation and math\n",
    "#\n",
    "# import numpy as np\n",
    "# import scipy as sp\n",
    "import pandas as pd\n",
    "#\n",
    "# plotting and visualization\n",
    "#\n",
    "# import matplotlib as mpl\n",
    "# import matplotlib.cm as cm\n",
    "# from matplotlib.colors import ListedColormap\n",
    "# import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#\n",
    "# modeling\n",
    "#\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "# from sklearn.preprocessing import OneHotEncoder as OHE\n",
    "# import sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score, f1_score\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "print(\"Loaded Libraries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ebb270",
   "metadata": {},
   "source": [
    "## Categorical Variables\n",
    "\n",
    "In general, categorical features need to be transformed or encoded to be used in some machine learning models, as is the case for Logistic Regression. A common transformation is so-called dummy encoding, where each possible value of a feature becomes a new column, and a 1 is placed in that column if the data instance (a row of the data) contained that value, and a 0 is placed in that column otherwise.\n",
    "\n",
    "For example, suppose we had a column in a hypothetical data set called species, and it contained one of two values, \"cat\" or \"dog\". The column might look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6be4d938",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflog = pd.read_csv(\"../data/processed/products.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b32eacc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b997f333",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Brand', 'Size', 'ParentCategory', 'Category', 'Color'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m categorical_features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBrand\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      2\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSize\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParentCategory\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCategory\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColor\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDescription\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m dflog \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(dflog, columns \u001b[38;5;241m=\u001b[39m categorical_features)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe data have \u001b[39m\u001b[38;5;124m'\u001b[39m, dflog\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m rows and \u001b[39m\u001b[38;5;124m'\u001b[39m, dflog\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m columns\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn names: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/encoding.py:169\u001b[0m, in \u001b[0;36mget_dummies\u001b[0;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput must be a list-like for parameter `columns`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     data_to_encode \u001b[38;5;241m=\u001b[39m data[columns]\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# validate prefixes and separator to avoid silently dropping cols\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_len\u001b[39m(item, name: \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:4096\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4095\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4096\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4098\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Brand', 'Size', 'ParentCategory', 'Category', 'Color'] not in index\""
     ]
    }
   ],
   "source": [
    "categorical_features = ['Brand',\n",
    "                        'Size',\n",
    "                        'Color', \n",
    "                        'Description']\n",
    "'ParentCategory'\n",
    "'Category'\n",
    "dflog = pd.get_dummies(dflog, columns = categorical_features)\n",
    "print('The data have ', dflog.shape[0], ' rows and ', dflog.shape[1], ' columns\\n')\n",
    "print('column names: \\n')\n",
    "print('\\n'.join(list(dflog.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac7ed53",
   "metadata": {},
   "source": [
    "#### Proportion of classes\n",
    "When building classification models, it is always a good idea to know right away the number of samples per class, proportionally to the total number of samples. First we get the counts of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "329909bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Category'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Category'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m class_counts \u001b[38;5;241m=\u001b[39m dflog[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCategory\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n\u001b[1;32m      2\u001b[0m class_counts\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Category'"
     ]
    }
   ],
   "source": [
    "class_counts = dflog['Category'].value_counts()\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c65fc1ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'class_counts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m class_percentages \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries([(x \u001b[38;5;241m/\u001b[39m dflog\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100.00\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m class_counts])\n\u001b[1;32m      2\u001b[0m class_percentages\n",
      "\u001b[0;31mNameError\u001b[0m: name 'class_counts' is not defined"
     ]
    }
   ],
   "source": [
    "class_percentages = pd.Series([(x / dflog.shape[0]) * 100.00 for x in class_counts])\n",
    "class_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b4971e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.bar(class_counts.index, class_counts)\n",
    "# ax.set_xticks([0, 1])\n",
    "# ax.set_xticklabels(class_percentages.index.astype(str) + '\\n' + ' ' +\n",
    "#                    class_percentages.round(0).astype(str) + '%')\n",
    "# ax.set_ylabel('Count')\n",
    "# ax.set_xlabel('Category')\n",
    "# ax.set_title('Heart Disease class distribution\\nwhere 1 means presence of heart disease',\n",
    "#               fontsize = 10)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4e5909",
   "metadata": {},
   "source": [
    "Are there Imbalanced Multi-Class Classification Problems--IMCP going on here?? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a82da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def points_plot(ax, Xtr, Xte, ytr, yte, \n",
    "                clf, \n",
    "                mesh = True, colorscale = cmap_light, cdiscrete = cmap_bold, \n",
    "                alpha = 0.1, psize = 10, \n",
    "                zfunc = False, predicted = False):\n",
    "#\n",
    "# note: this function only works for X.shape = (:, 2)\n",
    "# it is intended to illustrate the classifier boundary\n",
    "#\n",
    "# get the column names if they exist to apply\n",
    "# to the meshed data generated below\n",
    "#\n",
    "    try:\n",
    "        feature_names = Xtr.columns\n",
    "    except:\n",
    "        feature_names = None\n",
    "#        \n",
    "    Xtrain = np.array(Xtr)\n",
    "    Xtest = np.array(Xte)\n",
    "#\n",
    "    h = 0.02\n",
    "#\n",
    "# create a uniform grid spanning the range of the X values\n",
    "# note that y here is NOT the target, it is the 2nd\n",
    "# dimension of the desired plot\n",
    "#\n",
    "    X = np.concatenate((Xtrain, Xtest))\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                         np.linspace(y_min, y_max, 100))\n",
    "#\n",
    "# predict the target value at each point in the grid\n",
    "#\n",
    "# this method uses the probabilities from the classifier\n",
    "# and applies a function to determine the class\n",
    "#\n",
    "    if zfunc:\n",
    "        mesh_data = np.c_[xx.ravel(), yy.ravel()]\n",
    "        if feature_names is not None:\n",
    "            mesh_data = pd.DataFrame(mesh_data, \n",
    "                         columns = feature_names)\n",
    "        p0 = clf.predict_proba(mesh_data)[:, 0]\n",
    "        p1 = clf.predict_proba(mesh_data)[:, 1]\n",
    "        Z = zfunc(p0, p1)\n",
    "#\n",
    "# this method uses the classifier to predict the classes directly\n",
    "#\n",
    "    else:\n",
    "        mesh_data = np.c_[xx.ravel(), yy.ravel()]\n",
    "        if feature_names is not None:\n",
    "            mesh_data = pd.DataFrame(mesh_data, \n",
    "                                     columns = feature_names)\n",
    "        Z = clf.predict(mesh_data)\n",
    "    ZZ = Z.reshape(xx.shape)\n",
    "#\n",
    "# plt.pcolormesh() creates a shaded result over the grid\n",
    "#\n",
    "    if mesh:\n",
    "        plt.pcolormesh(xx, yy, ZZ, \n",
    "                       cmap = cmap_light, \n",
    "                       alpha = alpha, \n",
    "                       axes = ax, \n",
    "                       shading = 'auto')\n",
    "#\n",
    "# add the points to the plot\n",
    "# these can be the original target values\n",
    "# or the predicted values\n",
    "#\n",
    "    if predicted:\n",
    "        showtr = clf.predict(Xtr)\n",
    "        showte = clf.predict(Xte)\n",
    "    else:\n",
    "        showtr = ytr\n",
    "        showte = yte\n",
    "#\n",
    "# plot training points\n",
    "#\n",
    "    ax.scatter(Xtrain[:, 0], Xtrain[:, 1], \n",
    "               c = showtr - 1, \n",
    "               cmap = cmap_bold, \n",
    "               s = psize, \n",
    "               alpha = alpha, \n",
    "               edgecolor = \"k\")\n",
    "#    \n",
    "# plot testing points\n",
    "#\n",
    "    ax.scatter(Xtest[:, 0], Xtest[:, 1],\n",
    "               c = showte - 1, \n",
    "               cmap = cmap_bold, \n",
    "               s = psize + 10,\n",
    "               alpha = alpha, \n",
    "               marker = \"s\")\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "#\n",
    "    return ax, xx, yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba3face",
   "metadata": {},
   "outputs": [],
   "source": [
    "def points_plot_prob(ax, Xtr, Xte, ytr, yte, \n",
    "                     clf, colorscale = cmap_light, cdiscrete = cmap_bold, \n",
    "                     ccolor = cm, \n",
    "                     alpha = 0.1, psize = 10):\n",
    "    try:\n",
    "        feature_names = Xtr.columns\n",
    "    except:\n",
    "        feature_names = None\n",
    "#        \n",
    "    Xtrain = np.array(Xtr)\n",
    "    Xtest = np.array(Xte)\n",
    "#    \n",
    "    ax, xx, yy = points_plot(ax, Xtr, Xte, ytr, yte,\n",
    "                         clf,\n",
    "                         mesh = False, \n",
    "                         colorscale = colorscale, cdiscrete = cdiscrete, \n",
    "                         psize = psize, alpha = alpha,\n",
    "                         predicted = True) \n",
    "    mesh_data = np.c_[xx.ravel(), yy.ravel()]\n",
    "    if feature_names is not None:\n",
    "        mesh_data = pd.DataFrame(mesh_data, \n",
    "                     columns = feature_names)    \n",
    "    Z = clf.predict_proba(mesh_data)[:, 1]\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, cmap = ccolor, alpha = 0.2)\n",
    "    cs2 = plt.contour(xx, yy, Z, cmap = ccolor, alpha = 0.6)\n",
    "    plt.clabel(cs2, fmt = '%2.1f', colors = 'k', fontsize = 12)\n",
    "#\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d055c094",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m encoder \u001b[38;5;241m=\u001b[39m OneHotEncoder(sparse_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Fit the encoder on the Brand feature\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m encoded_brand \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mfit_transform(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBrand\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Combine encoded Brand with numerical features (assuming you have some)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m combined_features \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([encoded_brand, df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCategory\u001b[39m\u001b[38;5;124m'\u001b[39m]]], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Create a OneHotEncoder object with sparse_output argument\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Fit the encoder on the Brand feature\n",
    "encoded_brand = encoder.fit_transform(df[['Brand']])\n",
    "\n",
    "# Combine encoded Brand with numerical features (assuming you have some)\n",
    "combined_features = pd.concat([encoded_brand, df[['Category']]], axis=1)\n",
    "\n",
    "# Use combined_features for KMeans clustering\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "kmeans.fit(combined_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a356702a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2db08c48",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sales' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 8\u001b[0m sales[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mholidays\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m sales[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSaleDate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(is_holiday)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sales' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcf1ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
