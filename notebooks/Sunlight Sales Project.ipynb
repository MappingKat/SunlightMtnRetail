{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44457917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import python_weather\n",
    "import asyncio\n",
    "\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "import holidays "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d326fb0",
   "metadata": {},
   "source": [
    "When are sales best? Is it correlated with weather? Snow for the mountain? Holidays? COVID because everytone had to get outside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02740516",
   "metadata": {},
   "outputs": [],
   "source": [
    "Compare sales data with placer cell phone data. Can we find trends and do some forecasting??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a3fd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories_list = pd.read_csv('../data/raw/category-list.csv')\n",
    "# inconsistent_categories = set(products['Category']).difference(categories_list)\n",
    "# print(len(inconsistent_categories))\n",
    "\n",
    "sales_csv = \"../data/raw/Sales 1-3-2024.csv\"\n",
    "sales_category_excel = \"../data/raw/Sales_By_Category_20231226_1648.xlsx\"\n",
    "sales_history_csv = \"../data/raw/Sales/2023 - Sunlight Ski and Bike Shop.csv\"\n",
    "# sales_cat = pd.read_excel(sales_category_excel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33f35cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_weather(city):\n",
    "    async with python_weather.Client(unit=python_weather.IMPERIAL) as client:\n",
    "        weather = await client.get(city)\n",
    "        return weather\n",
    "\n",
    "# Assuming you have a DataFrame 'historic_data' with a 'date' column\n",
    "sales['weather_type'] = None  # Initialize the new column\n",
    "sales['SaleDate'] = pd.to_datetime(sales['SaleDate'])\n",
    "# Loop through each row in the DataFrame\n",
    "for index, row in sales.iterrows():\n",
    "    date = row['SaleDate']\n",
    "    \n",
    "    # Convert the date to a string in the format used by the weather API\n",
    "    date_str = date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Use the get_weather function to fetch weather data for the date\n",
    "    weather = asyncio.run(get_weather('Glenwood Springs'))  # Replace 'New York' with your city\n",
    "\n",
    "    # Extract the weather information you are interested in (e.g., description, main, etc.)\n",
    "    weather_type = weather.current.weather['description']\n",
    "    \n",
    "    # Assign the weather type to the corresponding row in the DataFrame\n",
    "    sales.at[index, 'weather_type'] = weather_type\n",
    "\n",
    "# Display the updated DataFrame\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce47a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_holiday(x): \n",
    "    usa_holidays = holidays.UnitedStates()  # Use 'UnitedStates' instead of 'country_holidays('USA')'\n",
    "    if x in usa_holidays:  # Check if the date is in the list of holidays\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "sales['holidays'] = sales['SaleDate'].apply(is_holiday) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e7ec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = products\n",
    "\n",
    "# Define a list of stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Bag of Words (BoW) method\n",
    "vectorizer_bow = CountVectorizer(stop_words=stop_words)\n",
    "description_bow = vectorizer_bow.fit_transform(data['Description'])\n",
    "\n",
    "# TF-IDF (Term Frequency-Inverse Document Frequency) method\n",
    "vectorizer_tfidf = TfidfVectorizer(stop_words=stop_words)\n",
    "description_tfidf = vectorizer_tfidf.fit_transform(data['Description'])\n",
    "\n",
    "# Word Embeddings (Word2Vec) method\n",
    "word2vec_model = gensim.models.Word2Vec(sentences=data['Description'], vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "word_embeddings = []\n",
    "for word in data['Description']:\n",
    "    if word in word2vec_model.wv:\n",
    "        word_embeddings.append(word2vec_model.wv[word])\n",
    "    else:\n",
    "        word_embeddings.append(np.zeros(100))  # If word not present, use zero vector\n",
    "\n",
    "# Doc2Vec method\n",
    "# doc2vec_model = gensim.models.Doc2Vec(vector_size=100, min_count=2, epochs=40)\n",
    "# doc2vec_model.build_vocab(data['Description'])\n",
    "# doc2vec_model.train(data['Description'], total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)\n",
    "\n",
    "# TextCategorizer (spaCy) method\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Add the text categorizer component to the pipeline using its string name\n",
    "nlp.add_pipe('textcat')\n",
    "\n",
    "# Machine Learning Classification Algorithms\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['Description'], data['Category'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Support Vector Machine\": SVC()\n",
    "}\n",
    "\n",
    "# Evaluate each model\n",
    "for name, model in models.items():\n",
    "    if \"Naive Bayes\" in name:\n",
    "        model.fit(vectorizer_tfidf.transform(X_train), y_train)\n",
    "        y_pred = model.predict(vectorizer_tfidf.transform(X_test))\n",
    "    else:\n",
    "        model.fit(vectorizer_bow.transform(X_train), y_train)\n",
    "        y_pred = model.predict(vectorizer_bow.transform(X_test))\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Calculate precision\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Confusion Matrix:\\n{cm}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df68af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_model = Doc2Vec(vector_size=100, min_count=2, epochs=40)\n",
    "\n",
    "tokenized_descriptions = [description.split() for description in products['Description']]\n",
    "\n",
    "# Convert each document (product description) to a TaggedDocument object\n",
    "tagged_data = [TaggedDocument(words=words, tags=[str(i)]) for i, words in enumerate(tokenized_descriptions)]\n",
    "\n",
    "# Now tagged_data contains a list of TaggedDocument objects\n",
    "\n",
    "# Build vocabulary from the tagged data\n",
    "doc2vec_model.build_vocab(tagged_data)\n",
    "\n",
    "# Train the Doc2Vec model\n",
    "doc2vec_model.train(tagged_data, total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c6e8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case the libraries are not in the proper path\n",
    "# import sys\n",
    "# sys.executable\n",
    "\n",
    "# !/opt/homebrew/anaconda3/bin/python -m pip install xgboost fasttext nltk spacy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
